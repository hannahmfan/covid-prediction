{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ARIMA Residuals Model</h1>\n",
    "\n",
    "<p>This model first fits a standard erf curve to the cumulative deaths data for each county. Over the long term, this method tends to underpredict the cumulative deaths, especially in the larger counties. To account for this, we fit an erf curve up to varying dates before the start of our actual prediction boundary, then train an ARIMA forecasting model on the residuals of the curve. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erf\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "import pandas as pd\n",
    "from util import util\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Global Dataframes and Variables</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We import the sample_submission.csv file as a way of determining\n",
    "# the order of the rows in out output file\n",
    "sample_submission = pd.read_csv(\"../sample_submission.csv\")\n",
    "\n",
    "# The fips_key.csv file contains standard information about each county\n",
    "key = pd.read_csv(\"../data/us/processing_data/fips_key.csv\", encoding='latin-1')\n",
    "\n",
    "# Daily deaths contains the death count per day for each county.\n",
    "# Cumulative deaths contains the total death count for each county\n",
    "# by day.\n",
    "daily_deaths = pd.read_csv(\"../data/us/covid/nyt_us_counties_daily.csv\")\n",
    "cumulative_deaths = pd.read_csv(\"../data/us/covid/deaths.csv\")\n",
    "county_land_areas = pd.read_csv(\"../data/us/demographics/county_land_areas.csv\", encoding='latin1')\n",
    "county_population = pd.read_csv(\"../data/us/demographics/county_populations.csv\", encoding='latin1')\n",
    "mobility_data = pd.read_csv(\"../data/us/mobility/DL-us-m50.csv\", encoding='latin1')\n",
    "\n",
    "# List of all counties\n",
    "all_fips = key[\"FIPS\"].tolist()\n",
    "\n",
    "util = util(daily_deaths, cumulative_deaths, county_land_areas, county_population, mobility_data, key)\n",
    "\n",
    "MIN_TOTAL_DEATHS = 80\n",
    "MIN_DAYS_SINCE_FIRST_DEATH = 10\n",
    "\n",
    "# Relevant dates\n",
    "today = cumulative_deaths.columns[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Quantile Generating Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the quantiles for a given value and standard error\n",
    "# according to a normal distribution.\n",
    "def generate_quantiles(value, err):\n",
    "    if err == 0:\n",
    "        return [value] * 9\n",
    "    \n",
    "    quantiles = []\n",
    "    for quantile in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        quantiles.append(norm.ppf(quantile, loc=value, scale=err))\n",
    "\n",
    "    return quantiles\n",
    "\n",
    "# Generate quantiles for a given list of values and errors\n",
    "def generate_list_quantiles(lst, err_lst):\n",
    "    quantiles = []\n",
    "    for i in range(len(lst)):\n",
    "        quantiles.append(generate_quantiles(lst[i], err_lst[i]))\n",
    "\n",
    "    return quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Helpful Date Functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all dates used over the course of the term\n",
    "all_dates = sample_submission[\"id\"].values.copy()\n",
    "\n",
    "def extract_date_from_id(row_id):\n",
    "    split = row_id.split('-')\n",
    "    return '-'.join(split[:-1])\n",
    "\n",
    "for i in range(len(all_dates)):\n",
    "    all_dates[i] = extract_date_from_id(all_dates[i])\n",
    "\n",
    "# Remove duplicates in the list\n",
    "all_dates = list(dict.fromkeys(all_dates))\n",
    "\n",
    "# Assume date is in format mm/dd/yy, convert to yyyy-mm-dd\n",
    "def convert_date_to_yyyy_mm_dd(date):\n",
    "    parts = date.split('/')\n",
    "    \n",
    "    # Ensure leading zeros if necessary\n",
    "    if len(parts[0]) == 1:\n",
    "        parts[0] = \"0\" + parts[0]\n",
    "    \n",
    "    if len(parts[1]) == 1:\n",
    "        parts[1] = \"0\" + parts[1]\n",
    "        \n",
    "    return \"2020\" + \"-\" + parts[0] + \"-\" + parts[1]\n",
    "\n",
    "# Assume date is in format yyyy-mm-dd, convert to mm/dd/yy\n",
    "def convert_date_to_mm_dd_yy(date):\n",
    "    parts = date.split('-')\n",
    "    \n",
    "    # Remove leading zeros if necessary\n",
    "    if parts[1][0] == \"0\":\n",
    "        parts[1] = parts[1][1:]\n",
    "    \n",
    "    if parts[2][0] == \"0\":\n",
    "        parts[2] = parts[2][1:]\n",
    "        \n",
    "    return parts[1] + \"/\" + parts[2] + \"/\" + \"20\"\n",
    "\n",
    "# Starting from a given date, take an input number of steps\n",
    "# and compute a list of dates containg the start date and\n",
    "# \"steps\" dates into the future or past, for a total of steps\n",
    "# dates.\n",
    "def get_dates_from_start(startDate, steps):\n",
    "    if steps > 0:\n",
    "        dates = all_dates[all_dates.index(startDate):all_dates.index(startDate) + steps]\n",
    "    else:\n",
    "        dates = all_dates[all_dates.index(startDate) + steps:all_dates.index(startDate)]\n",
    "    return dates\n",
    "\n",
    "# Get the next date of a given date\n",
    "def get_next_date(startDate):\n",
    "    return get_dates_from_start(startDate, 2)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Functions Used for Curve Fitting</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erf_curve(times, log_max, slope, center):\n",
    "    max_val = 10 ** log_max\n",
    "    deaths = max_val * (1 + erf(slope * (times - center)))\n",
    "    return deaths\n",
    "\n",
    "def eval_erf(times, coefs):\n",
    "    max_val = 10 ** coefs[0]\n",
    "    deaths = max_val * (1 + erf(coefs[1] * (times - coefs[2])))\n",
    "    return deaths\n",
    "\n",
    "def linear_curve(times, slope, intercept):\n",
    "    return [x * slope for x in times] + intercept\n",
    "\n",
    "def constant_curve(times, c):\n",
    "    return [x * c for x in times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of daily deaths, compute a list of cumulative\n",
    "# deaths of the same length\n",
    "def get_cumulative_from_daily(daily):\n",
    "    cumulative = []\n",
    "    curr = 0\n",
    "    for deaths in daily:\n",
    "        curr += deaths\n",
    "        cumulative.append(curr)\n",
    "    \n",
    "    return cumulative\n",
    "\n",
    "# Given a fips and end date, fit an erf curve to the cumulative deaths\n",
    "# of the county and return the coefficients\n",
    "def get_erf_curve(fips, endDate):\n",
    "    daily_deaths_list = util.get_deaths_list(fips, endDate=endDate)\n",
    "    cumulative_deaths_list = get_cumulative_from_daily(daily_deaths_list)\n",
    "\n",
    "    # Compute x and y lists to pass to curve_fit\n",
    "    x = [i for i in range(len(cumulative_deaths_list))]\n",
    "    y = cumulative_deaths_list\n",
    "    \n",
    "    assert len(y) >= MIN_DAYS_SINCE_FIRST_DEATH and y[-1] > MIN_TOTAL_DEATHS\n",
    "    popt, pcov = curve_fit(erf_curve, x, y, maxfev=10000)\n",
    "    \n",
    "    return popt\n",
    "\n",
    "def get_erf_residuals(fips, end_train_date, n_steps):\n",
    "    train_daily_deaths = util.get_deaths_list(fips, endDate=end_train_date)\n",
    "    all_daily_deaths = util.get_deaths_list(fips, endDate=convert_date_to_yyyy_mm_dd(today))\n",
    "    \n",
    "    # Get an optimal erf curve fit for this county up to end_train_date\n",
    "    erf_coefs = get_erf_curve(fips, end_train_date)\n",
    "    \n",
    "    # Ensure that there are n_steps more dates after the end of the train date\n",
    "    assert len(train_daily_deaths) + n_steps <= len(all_daily_deaths)\n",
    "    \n",
    "    # Generate an input array to evaluate predictions on the coming n_steps dates\n",
    "    x_input = []\n",
    "    for i in range(len(train_daily_deaths), len(train_daily_deaths) + n_steps):\n",
    "        x_input.append(i)\n",
    "    \n",
    "    cumulative_train_deaths = get_cumulative_from_daily(train_daily_deaths)\n",
    "    all_cumulative_deaths = get_cumulative_from_daily(all_daily_deaths)\n",
    "    \n",
    "    # Make predictions for the next n_steps days\n",
    "    predictions = []\n",
    "    for i in x_input:\n",
    "        predictions.append(eval_erf(i, erf_coefs))\n",
    "    \n",
    "    # Compute the residuals of the predictions\n",
    "    residuals = []\n",
    "    for i, pred in enumerate(predictions):\n",
    "        residuals.append(all_cumulative_deaths[x_input[i]] - pred)\n",
    "        \n",
    "    assert len(residuals) == n_steps\n",
    "    \n",
    "    return residuals, erf_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_list():\n",
    "    return sample_submission[\"id\"].values\n",
    "\n",
    "def extract_date_from_id(row_id):\n",
    "    split = row_id.split('-')\n",
    "    return '-'.join(split[:-1])\n",
    "\n",
    "def extract_fips_from_id(row_id):\n",
    "    return row_id.split('-')[-1]\n",
    "\n",
    "def train_arima(trainData, order=(2, 1, 0)):\n",
    "    model = ARIMA(trainData, order=order)\n",
    "    model_fit = model.fit(disp=0)\n",
    "\n",
    "    return model_fit\n",
    "\n",
    "def get_residuals_predictions(train_residuals, n_steps, order=(2, 1, 0)):\n",
    "    try:\n",
    "        model = train_arima(train_residuals, order=order)\n",
    "    except:\n",
    "        average = np.mean(train_residuals)\n",
    "        return [average] * n_steps\n",
    "    \n",
    "    forecast = model.forecast(steps=n_steps)[0]\n",
    "    return list(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/minpack.py:795: OptimizeWarning: Covariance of the parameters could not be estimated\n",
      "  category=OptimizeWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/tsa/tsatools.py:672: RuntimeWarning: divide by zero encountered in arctanh\n",
      "  invarcoefs = 2*np.arctanh(params)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:548: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  'available', HessianInversionWarning)\n",
      "/usr/local/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Size: 13\n",
      "Window Size: 14\n",
      "Window Size: 15\n"
     ]
    }
   ],
   "source": [
    "n_pred_steps = 18\n",
    "\n",
    "last_train_date = \"2020-05-22\"\n",
    "dates_to_consider = get_dates_from_start(get_next_date(last_train_date), n_pred_steps)\n",
    "\n",
    "for n_erf_pred_steps in range(7, 16):\n",
    "    print(\"Window Size: \" + str(n_erf_pred_steps))\n",
    "    # Train an erf curve fitting model up until two weeks before the \n",
    "    # last train date. This residuals map will store for each fips\n",
    "    # passing a certain threshold number of deaths a list of the\n",
    "    # residuals up until the last train date.\n",
    "    residuals_map = {}\n",
    "    erf_coefs_map = {}\n",
    "\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for fips in all_fips:\n",
    "        last_erf_train_date = get_dates_from_start(dates_to_consider[0], -(n_erf_pred_steps + 1))[0]\n",
    "\n",
    "        daily_deaths_list = util.get_deaths_list(fips, endDate=last_erf_train_date)\n",
    "        cumulative_deaths_list = get_cumulative_from_daily(daily_deaths_list)\n",
    "\n",
    "        if len(cumulative_deaths_list) <= MIN_DAYS_SINCE_FIRST_DEATH or cumulative_deaths_list[-1] <= MIN_TOTAL_DEATHS:\n",
    "            continue\n",
    "\n",
    "        residuals, erf_coefs = get_erf_residuals(fips, last_erf_train_date, n_erf_pred_steps)\n",
    "\n",
    "        residuals_map[fips] = residuals\n",
    "        erf_coefs_map[fips] = erf_coefs\n",
    "\n",
    "    #############################################\n",
    "    ##### Store predictions in a dictionary #####\n",
    "    #############################################\n",
    "\n",
    "    stderr = 0.6\n",
    "    data = {}\n",
    "    for fips in all_fips:\n",
    "        if fips in [44001, 44003, 44005, 44007, 44009]:\n",
    "            continue\n",
    "            \n",
    "        data[fips] = {}\n",
    "\n",
    "        daily_deaths_list = util.get_deaths_list(fips, endDate=last_train_date)\n",
    "        cumulative_deaths_list = get_cumulative_from_daily(daily_deaths_list)\n",
    "\n",
    "        if (len(cumulative_deaths_list) == 0) or (not fips in residuals_map and cumulative_deaths_list[-1] < 20):\n",
    "            for i, date in enumerate(dates_to_consider):\n",
    "                data[fips][date] = [0] * 9\n",
    "        elif not fips in residuals_map and cumulative_deaths_list[-1] >= 20:\n",
    "            # Fit a linear model to the last 20 points of data\n",
    "            length = min(20, len(daily_deaths_list))\n",
    "            x_input = [i for i in range(length)]\n",
    "\n",
    "            popt, pcov = curve_fit(linear_curve, x_input, daily_deaths_list[-length:], maxfev=10000)\n",
    "\n",
    "            x_preds = [i + length for i in range(n_pred_steps)]\n",
    "            output = linear_curve(x_preds, popt[0], popt[1])\n",
    "            errors = [x * stderr for x in output]\n",
    "\n",
    "            quantiles = generate_list_quantiles(output, errors)\n",
    "            for i, date in enumerate(dates_to_consider):\n",
    "                data[fips][date] = quantiles[i]\n",
    "\n",
    "        else:\n",
    "            residuals = residuals_map[fips]\n",
    "            erf_coefs = erf_coefs_map[fips]\n",
    "\n",
    "            daily_deaths = util.get_deaths_list(fips, endDate=last_train_date)\n",
    "            cumulative_deaths = get_cumulative_from_daily(daily_deaths)\n",
    "\n",
    "            residuals_predictions = get_residuals_predictions(residuals, n_pred_steps)\n",
    "            x_in = [i + len(cumulative_deaths) for i in range(0, n_pred_steps)]\n",
    "            erf_predictions = eval_erf(x_in, erf_coefs)\n",
    "\n",
    "            final_predictions = list(residuals_predictions + erf_predictions)\n",
    "            final_predictions.insert(0, cumulative_deaths[-1])\n",
    "            final_predictions = np.diff(final_predictions)\n",
    "\n",
    "            errors = [x * stderr for x in final_predictions]\n",
    "\n",
    "            quantiles = generate_list_quantiles(final_predictions, errors)\n",
    "\n",
    "            for i, date in enumerate(dates_to_consider):\n",
    "                data[fips][date] = quantiles[i]\n",
    "\n",
    "    ###########################\n",
    "    ##### Export to a CSV #####\n",
    "    ###########################\n",
    "\n",
    "    lists = []\n",
    "    for row_id in get_id_list():\n",
    "        date = extract_date_from_id(row_id)\n",
    "        fips = int(extract_fips_from_id(row_id))\n",
    "        \n",
    "        if not fips in data:\n",
    "            lst = [row_id] + [\"%.2f\" % 0.00] * 9\n",
    "            lists.append(lst)\n",
    "            continue\n",
    "\n",
    "        if not date in data[fips]:\n",
    "            lst = [row_id] + [\"%.2f\" % 0.00] * 9\n",
    "            lists.append(lst)\n",
    "            continue\n",
    "\n",
    "        quantiles = data[fips][date]\n",
    "        lst = [row_id]\n",
    "        for q in quantiles:\n",
    "            if str(q) == \"nan\":\n",
    "                lst.append(\"%.2f\" % 0.00)\n",
    "            elif q < 0:\n",
    "                lst.append(\"%.2f\" % 0.00)\n",
    "            else:\n",
    "                lst.append(\"%.2f\" % q)\n",
    "\n",
    "        lists.append(lst)\n",
    "\n",
    "    df = pd.DataFrame(lists, columns=sample_submission.columns)\n",
    "    df.to_csv(\"arima_residuals_predictions_\" + str(n_erf_pred_steps) +  \".csv\", index=False, sep=',')\n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = pd.read_csv(\"arima_residuals_predictions_7.csv\")\n",
    "predictions2 = pd.read_csv(\"arima_residuals_predictions_8.csv\")\n",
    "predictions3 = pd.read_csv(\"arima_residuals_predictions_9.csv\")\n",
    "predictions4 = pd.read_csv(\"arima_residuals_predictions_10.csv\")\n",
    "predictions5 = pd.read_csv(\"arima_residuals_predictions_11.csv\")\n",
    "predictions6 = pd.read_csv(\"arima_residuals_predictions_12.csv\")\n",
    "predictions7 = pd.read_csv(\"arima_residuals_predictions_13.csv\")\n",
    "predictions8 = pd.read_csv(\"arima_residuals_predictions_14.csv\")\n",
    "predictions9 = pd.read_csv(\"arima_residuals_predictions_15.csv\")\n",
    "\n",
    "cols = ['id', '10', '20', '30', '40', '50', '60', '70', '80', '90']\n",
    "\n",
    "averaged_predictions = pd.DataFrame(columns=cols)\n",
    "averaged_predictions['id'] = predictions1['id']\n",
    "\n",
    "for col in cols[1:]:\n",
    "    averaged_predictions[col] = predictions1[col] * 1/9 + predictions2[col] * 1/9 + predictions3[col] * 1/9 + predictions4[col] * 1/9 + predictions5[col] * 1/9 + predictions6[col] * 1/9 + predictions7[col] * 1/9 + predictions8[col] * 1/9 + predictions9[col] * 1/9\n",
    "\n",
    "averaged_predictions.to_csv(\"averaged_arima_predictions.csv\", index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
