{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Imported for its helper functions\n",
    "import imperial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = pd.read_csv(\"submissions/arima_model_5-24.csv\")\n",
    "predictions2 = pd.read_csv(\"submissions/arima_residuals_5-24.csv\")\n",
    "predictions3 = pd.read_csv(\"submissions/benchmark_5-24.csv\")\n",
    "predictions4 = pd.read_csv(\"submissions/case_model_5-24.csv\")\n",
    "predictions5 = pd.read_csv(\"submissions/delphi_5-24.csv\")\n",
    "predictions6 = pd.read_csv(\"submissions/historian_model_5-24.csv\")\n",
    "predictions7 = pd.read_csv(\"submissions/imperial_model_5-24.csv\")\n",
    "predictions8 = pd.read_csv(\"submissions/rnn_residuals_5-24.csv\")\n",
    "predictions9 = pd.read_csv(\"submissions/svm_5-24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperial_fips = set(imperial_model.get_top_cumuluative_death_counties(30, \"2020-05-24\"))\n",
    "historian_fips = set(imperial_model.get_top_cumuluative_death_counties(100, \"2020-05-24\")[30:])\n",
    "case_model_fips = set(imperial_model.get_top_cumuluative_death_counties(100, \"2020-05-24\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the quantiles for a given value and standard error\n",
    "# according to a normal distribution.\n",
    "def generate_quantiles(value, err):\n",
    "    if err == 0:\n",
    "        return [value] * 9\n",
    "    \n",
    "    quantiles = []\n",
    "    for quantile in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        quantiles.append(norm.ppf(quantile, loc=value, scale=err))\n",
    "\n",
    "    return quantiles\n",
    "\n",
    "def extract_date_from_id(row_id):\n",
    "    split = row_id.split('-')\n",
    "    return '-'.join(split[:-1])\n",
    "\n",
    "def extract_fips_from_id(row_id):\n",
    "    return row_id.split('-')[-1]\n",
    "\n",
    "sample_submission = pd.read_csv(\"../sample_submission.csv\")\n",
    "\n",
    "dates_of_interest = ['2020-05-25', '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29', '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02', '2020-06-03', '2020-06-04', '2020-06-05', '2020-06-06', '2020-06-07']\n",
    "\n",
    "lists = []\n",
    "for row_id in sample_submission[\"id\"].values:\n",
    "    print(row_id)\n",
    "    \n",
    "    fips = int(extract_fips_from_id(row_id))\n",
    "    date = extract_date_from_id(row_id)\n",
    "    \n",
    "    if date not in dates_of_interest:\n",
    "        lists.append([row_id] + ['{0:.2f}'.format(0)] * 9)\n",
    "        continue\n",
    "    \n",
    "    if fips in [44001, 44003, 44005, 44007, 44009]:\n",
    "        lists.append([row_id] + [0] * 9)\n",
    "        continue\n",
    "    \n",
    "    # Query to access the value in any dataframe\n",
    "    query = \"id==\" + \"\\\"\" + date + \"-\" + str(fips) + \"\\\"\"\n",
    "    \n",
    "    arima            = list(predictions1.query(query).values[0])[5]\n",
    "    arima_residuals  = list(predictions2.query(query).values[0])[5]\n",
    "    benchmark        = list(predictions3.query(query).values[0])[5]\n",
    "    \n",
    "    case             = list(predictions4.query(query).values[0])[5]\n",
    "    \n",
    "    # Impose guards against extreme upper outliers\n",
    "    if fips not in imperial_fips:\n",
    "        case = min(20, case)\n",
    "    else:\n",
    "        case = min(120, case)\n",
    "    \n",
    "    delphi           = list(predictions5.query(query).values[0])[5]\n",
    "    \n",
    "    historian        = list(predictions6.query(query).values[0])[5]\n",
    "    \n",
    "    # Impose guards against extreme upper outliers\n",
    "    historian = min(20, historian)\n",
    "    \n",
    "    imperial         = list(predictions7.query(query).values[0])[5]\n",
    "    rnn_residuals    = list(predictions8.query(query).values[0])[5]\n",
    "    svm              = list(predictions9.query(query).values[0])[5]\n",
    "    \n",
    "    # Impose guards against extreme upper outliers\n",
    "    if fips not in imperial_fips:\n",
    "        svm = min(20, svm)\n",
    "    else:\n",
    "        svm = min(120, svm)\n",
    "    \n",
    "    quantiles = []\n",
    "    \n",
    "    if fips == 36061:\n",
    "        median_pred = arima * 0.1 + arima_residuals * 0.1 + case * 0.15 + imperial * 0.6 + svm * 0.05\n",
    "        \n",
    "        # Guard against extremely large values\n",
    "        median_pred = min(median_pred, 120)\n",
    "        \n",
    "        quantiles = generate_quantiles(median_pred, median_pred * 0.6)\n",
    "    elif fips in imperial_fips:\n",
    "        median_pred = arima * 0.05 + arima_residuals * 0.1 + benchmark * 0.05 + case * 0.15 + delphi * 0.05 + imperial * 0.5 + rnn_residuals * 0.05 + svm * 0.05\n",
    "        \n",
    "        # Guard against extremely large values\n",
    "        median_pred = min(median_pred, 120)\n",
    "        \n",
    "        quantiles = generate_quantiles(median_pred, median_pred * 0.6)\n",
    "    elif fips in historian_fips:\n",
    "        median_pred = arima * 0.15 + arima_residuals * 0.2 + benchmark * 0.1 + case * 0.2 + delphi * 0.15 + rnn_residuals * 0.1 + svm * 0.1\n",
    "        \n",
    "        # Guard against extremely large values\n",
    "        median_pred = min(20, median_pred)\n",
    "        \n",
    "        quantiles = generate_quantiles(median_pred, median_pred * 0.6)\n",
    "    else:\n",
    "        recent_deaths = list(imperial_model.imperial_util.get_deaths_list(fips, endDate=\"2020-05-24\"))[-14:]\n",
    "        zero_count = recent_deaths.count(0)\n",
    "\n",
    "        if len(recent_deaths) > 0:\n",
    "            total_deaths = np.sum(recent_deaths) - np.max(recent_deaths)\n",
    "        else:\n",
    "            total_deaths = 0\n",
    "\n",
    "        # Apply manual heuristics for very small counties, or determine predictions as a combination\n",
    "        # of the remaining predictions files.\n",
    "        if len(recent_deaths) == 14 and total_deaths < 30:\n",
    "            if total_deaths > 20 and zero_count < 8:\n",
    "                quantiles = [0, 0, 1, 1, 2, 2, 3, 3, 4]\n",
    "            elif total_deaths > 10 and zero_count < 8:\n",
    "                quantiles = [0, 0, 0, 0, 1, 1, 1, 2, 2]\n",
    "            elif total_deaths > 5 and zero_count < 10:\n",
    "                quantiles = [0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "            else:\n",
    "                quantiles = [0] * 9\n",
    "        else:\n",
    "            median_pred = arima * 0.2 + arima_residuals * 0.2 + benchmark * 0.1 + delphi * 0.2 + rnn_residuals * 0.1 + svm * 0.2\n",
    "            \n",
    "            # Guard against extremely large values\n",
    "            median_pred = min(10, median_pred)\n",
    "            \n",
    "            quantiles = generate_quantiles(median_pred, median_pred * 0.6)\n",
    "    \n",
    "    for i in range(len(quantiles)):\n",
    "        if str(quantiles[i]) == \"nan\":\n",
    "            quantiles[i] = 0\n",
    "\n",
    "        quantiles[i] = max(quantiles[i], 0)\n",
    "        \n",
    "    # Round down for lower quantiles\n",
    "    for i in range(5):\n",
    "        quantiles[i] = math.floor(quantiles[i])\n",
    "        \n",
    "    for i in range(5, 9):\n",
    "        quantiles[i] = math.ceil(quantiles[i])\n",
    "    \n",
    "    for i in range(0, 9):\n",
    "        quantiles[i] = '{0:.2f}'.format(quantiles[i])\n",
    "    \n",
    "    lists.append([row_id] + quantiles)\n",
    "        \n",
    "df = pd.DataFrame(lists, columns=sample_submission.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_submission_2.csv\", index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_quantiles(2, 0.6 * 2)\n",
    "[0.00,0.00,0.00,1.00,2.00,2.00,2.00,3.00,3.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
